---
title: "generalized mixed linear model: marginal versus conditional effects"
author: "Ward B. Eiling"
format: html
bibliography: GLMM_references.bib
---

In this document, we will shed light on an issue that is well-known in the field of generalized linear mixed models (GLMMs), namely the discrepancy between population-averaged (PA; i.e., marginal) and subject-specific (SS; i.e., conditional-on-the-random-effect) interpretations of a fixed slope when the link function is non-linear. Note that subject-specific does not implicate the presence of a random slope. The main distinction between SS and PA models is whether the regression coefficients describe an individual's or the average population response to changing $x$ [@Zeger1988]. An excellent example between the two is given by @Zeger1998:

> "For example, if $x_{it}$, indicates whether subject $i$ smokes at time $t$, and Yit is the presence/absence of respiratory infection, the PA model estimates the difference in infection rates between smokers and nonsmokers; the SS model estimates the expected change in an individual's probability of infection given a change in smoking status." (p. 1051)

This document will explain why a discrepancy between the PA and SS interpretations of the fixed slope arises when the link function is non-linear. In this treatment, we will focus on very simple GLMMs with only one predictor and a random intercept.

## Generalized Mixed Linear Model with Non-linear Logit Function

In this document, we will reproduce the figure made by Dimitri Rizopoulos in de course [CE08](https://www.drizopoulos.com/courses/EMC/CE08.pdf) (slide 321), where the generalized mixed linear model (GLMM) with a non-linear logit function results in a discrepancy between the marginal and conditional relationships (see also @Zeger1988 for the similar and original treatment). Let us consider the following GLMM

$$
\text{log} \frac{\pi_{it}}{1-\pi_{it}} = \beta_0 + \beta_1 X_{it} + b_{0i} + \epsilon_{it} \quad b_{0i} \sim \mathcal{N}(0,\sigma_{b0}^2)
$$

Where $\pi_{it} = Pr(Y_{it} = 1)$ the probability of a positive response for subject $i$ at time $t$, $Y_{it}$ is the binary response variable, $X_{it}$ is the continuous covariate, $A_{it}$ is the binary treatment indicator, and $b_{0i}$ is the random intercept. The fixed effects are $\beta_0$ and $\beta_1$ for the intercept and the continuous covariate. The random intercept $b_{0i}$ is assumed to be normally distributed with mean zero and variance $\sigma_{b0}^2$.

We specify the following parameter values

-   $\beta_0 = 0$
-   $\beta_1 = 0.5$
-   $\sigma_{b0}^2 = 0.5$

For simplicity, this model does not include a treatment effect $A_{it}$ nor exogenous noise $\epsilon_{it}$. Now we will simulate data from this model and directly infer the relationships between the continuous covariate $X_{it}$ and the probability of a positive response $\pi_{it}$.

```{r}
#| label: fig-marginal-vs-conditional
#| fig.width: 10
#| fig.height: 8

set.seed(123) # For reproducibility

# Parameters
beta_0 <- 0 # for simplicity
beta_1 <- 0.9
sigma_b0 <- sqrt(4)

n_individuals <- 20 # Number of individuals to plot
X_grid <- seq(-5, 5, length.out = 10000) # Values for X_it

# Generate random intercepts for individuals
b0 <- rnorm(n_individuals, mean = 0, sd = sigma_b0)

# Conditional-level logit and probability: the mean individual (b0 = 0)
logit_conditional <- beta_0 + beta_1 * X_grid + 0 # expected value
pi_conditional <- 1 / (1 + exp(-logit_conditional))

# Individual-specific logits and probabilities
logit_individuals <- sapply(b0, function(b) beta_0 + beta_1 * X_grid + b) # expected value
pi_individuals <- 1 / (1 + exp(-logit_individuals))

# Population-level logit and probability: average probabilities across individuals
pi_population <- rowMeans(pi_individuals)

# save the upcoming plot
png("figure/fig-marginal-vs-conditional.png", width = 1200, height = 1000, res = 150)

# Plot the conditional-level curve
plot(X_grid, pi_conditional, type = "l", lwd = 4, col = "black",
     ylim = c(0, 1), xlim = c(-5, 5), xlab = expression(X[it]), ylab = "Probability",
     main = "Population, Conditional and Individual Logit Curves")

# Add individual curves (grey lines)
for (i in 1:n_individuals) {
  lines(X_grid, pi_individuals[, i], col = "grey", lwd = 1)
}

# add the population-level curve (red line)
lines(X_grid, pi_population, col = "red", lwd = 4)

# Add a legend
legend("topleft", legend = c("conditional", "population", "individuals"),
       col = c("black", "red",  "grey"), lty = c(1, 1, 1), lwd = c(4, 4, 1))

dev.off()
```

When we estimate the GLMM with the log link function, we obtain the conditional-on-the-random effects interpretation of fixed-effects regression coefficients (i.e., the effects of covariates on changes in an individualâ€™s transformed mean response). This is directly opposed by marginal models such as GEE, where "population averages are the targets of inference" (Rizopoulos, CE08, p. 331)

Let's now take the scenario where the predictor $X_{it}$ is a binary variable.

```{r}
#| label: fig-overlay-logistic
#| fig.width: 10
#| fig.height: 8

set.seed(123) # For reproducibility

# Parameters
beta_0 <- 0
beta_1 <- 5
sigma_b0 <- sqrt(4)

n_individuals <- 20 # Number of individuals to plot

# Continuous logistic predictor
X_grid_cont <- seq(0, 1, length.out = 10000)

# Binary predictor
X_grid_bin <- c(0, 1)

# Generate random intercepts for individuals
b0 <- rnorm(n_individuals, mean = 0, sd = sigma_b0)

# Continuous predictor: Compute conditional and individual probabilities
logit_conditional <- beta_0 + beta_1 * X_grid_cont
pi_conditional <- 1 / (1 + exp(-logit_conditional))

logit_individuals_cont <- sapply(b0, function(b) beta_0 + beta_1 * X_grid_cont + b)
pi_individuals_cont <- 1 / (1 + exp(-logit_individuals_cont))

pi_population_cont <- rowMeans(pi_individuals_cont)

# Binary predictor: Compute probabilities
logit_individuals_bin <- sapply(b0, function(b) outer(beta_0 + beta_1 * X_grid_bin, b, "+"))
pi_individuals_bin <- 1 / (1 + exp(-logit_individuals_bin))

pi_population_bin <- rowMeans(pi_individuals_bin)

# Plot the continuous logistic curve
plot(X_grid_cont, pi_conditional, type = "l", lwd = 4, col = "black",
     ylim = c(0, 1), xlim = c(0, 1), xlab = expression(X[it]), ylab = "Probability",
     main = "Binary Predictor with Interpolation of Logistic Curves")

# Add individual curves (grey lines) for continuous logistic function
for (i in 1:n_individuals) {
  lines(X_grid_cont, pi_individuals_cont[, i], col = "grey", lwd = 1)
}

# Add population-level curve (red line) for continuous logistic function
lines(X_grid_cont, pi_population_cont, col = "red", lwd = 4)

# Overlay binary predictor points (black and red)
points(X_grid_bin, 1 / (1 + exp(-(beta_0 + beta_1 * X_grid_bin))), col = "black", pch = 16, cex = 1.5)
for (i in 1:n_individuals) {
  points(X_grid_bin, pi_individuals_bin[, i], col = "grey", pch = 16, cex = 0.6)
}
points(X_grid_bin, pi_population_bin, col = "red", pch = 16, cex = 1.5)

# Add a legend
legend("topleft", legend = c("conditional (interpolation)", "population (interpolation)", "individuals (interpolation)", 
                             "datapoint conditional", "datapoint population", "datapoints individuals"),
       col = c("black", "red", "grey", "black", "red", "grey"), 
       lty = c(1, 1, 1, NA, NA, NA), 
       pch = c(NA, NA, NA, 16, 16, 16), 
       lwd = c(4, 4, 1, NA, NA, NA), pt.cex = c(NA, NA, NA, 1.5, 1.5, 0.6))

```

When we fit a GLMM with a log-link function and the variance of the random intercept is non-zero, the fixed effects are interpreted according to the subject-specific interpretation. As a result, GLMMs are most useful when the main scientific objective is to make inferences about individuals rather than population averages.

## Mixed Linear Model: Generalized Linear Mixed Model with Identity Link Function

Let us now consider a simple mixed linear model with a continuous outcome variable $Y_{it}$ and a continuous covariate $X_{it}$, where the random intercept $b_{0i}$ is normally distributed with mean zero and variance $\sigma_{b0}^2$. The model is given by

$$
Y_{it} = \beta_0 + \beta_1 X_{it} + b_{0i} + \epsilon_{it} \quad b_{0i} \sim \mathcal{N}(0,\sigma_{b0}^2)
$$

Where $\epsilon_{it}$ is the error term. We will simulate data from this model and directly infer the relationships between the continuous covariate $X_{it}$ and the outcome variable $Y_{it}$.

```{r}
#| label: fig-mixed-linear-model
#| fig.width: 10
#| fig.height: 8

set.seed(123) # For reproducibility

# Parameters
beta_0 <- 0 # for simplicity
beta_1 <- 0.2
sigma_b0 <- sqrt(4)

n_individuals <- 20 # Number of individuals to plot
X_grid <- seq(-5, 5, length.out = 10000) # Values for X_it

# Generate random intercepts for individuals
b0 <- rnorm(n_individuals, mean = 0, sd = sigma_b0)
expected_b0_is_zero = TRUE
if (expected_b0_is_zero == TRUE){
  b0 <- b0 - mean(b0)  # Centering step
}

# Conditional-level: the mean individual (b0 = 0)
expected_Y_conditional <- beta_0 + beta_1 * X_grid + 0

# Individual-specific
expected_Y_individuals <- sapply(b0, function(b) beta_0 + beta_1 * X_grid + b)

# Population-level: average probabilities across individuals
expected_Y_population <- rowMeans(expected_Y_individuals) # method 1
# expected_Y_population2 <- expected_Y_conditional + mean(b0) # method 2 (yields same result)

# save the upcoming plot
# png("figure/fig-marginal-vs-conditional.png", width = 1200, height = 1000, res = 150)

# Plot the conditional-level curve
plot(X_grid, expected_Y_conditional, type = "l", lwd = 4, col = "black",
     ylim = c(0, 1), xlim = c(-5, 5), xlab = expression(X[it]), ylab = "Probability",
     main = "Population, Conditional and Individual Logit Curves")

# Add individual curves (grey lines)
for (i in 1:n_individuals) {
  lines(X_grid, expected_Y_individuals[, i], col = "grey", lwd = 1)
}

# add the population-level curve (red line)
lines(X_grid, expected_Y_population, col = "red", lwd = 4)

# # add the population-level curve (orange line)
# lines(X_grid, expected_Y_population2, col = "orange", lwd = 4)

# Add a legend
legend("topleft", legend = c("conditional", "population", "individuals"),
       col = c("black", "red",  "grey"), lty = c(1, 1, 1), lwd = c(4, 4, 1))

# dev.off()
```

Now, we can see that while the population-averaged and subject-specific lines are parallel to one another, they are not equivalent due to the fact that the expected value (i.e., mean) of the random intercept is not exactly zero. One way of fixing this is (1) to simulate data with a very large sample size N and only show a certain amount in the plot or (2) to simulate data with a random intercept that is exactly zero. The latter is done in the code above by centering the random intercepts. However, when the expected value of the random intercept is zero, the population-averaged and subject-specific lines are equivalent, implying that both interpretations are valid.

```{r}
#| label: fig-marginal-vs-conditional-mlm
#| fig.width: 10
#| fig.height: 8

set.seed(123) # For reproducibility

# Parameters
beta_0 <- 0 # Intercept
beta_1 <- 0.9 # Slope
sigma_b0 <- sqrt(4) # Standard deviation of random intercepts

n_individuals <- 20 # Number of individuals to plot
X_grid <- seq(-5, 5, length.out = 10000) # Values for X_it

# Generate random intercepts for individuals
b0 <- rnorm(n_individuals, mean = 0, sd = sigma_b0)

# create centering option
expected_b0_is_zero = TRUE
if (expected_b0_is_zero == TRUE){
  b0 <- b0 - mean(b0)  # Centering step
}

# Conditional-level prediction (mean individual, b0 = 0)
y_conditional <- beta_0 + beta_1 * X_grid

# Individual-specific predictions
y_individuals <- sapply(b0, function(b) beta_0 + beta_1 * X_grid + b)

# Population-level prediction (average across individuals)
y_population <- rowMeans(y_individuals)

# Save the upcoming plot
# png("figure/fig-marginal-vs-conditional-mlm.png", width = 1200, height = 1000, res = 150)

# Plot the conditional-level curve
plot(X_grid, y_conditional, type = "l", lwd = 4, col = "black",
     ylim = range(y_individuals), xlim = c(-5, 5), xlab = expression(X[it]), ylab = expression(Y),
     main = "Population, Conditional, and Individual Response Curves")

# Add individual curves (grey lines)
for (i in 1:n_individuals) {
  lines(X_grid, y_individuals[, i], col = "grey", lwd = 1)
}

# Add the population-level curve (red line)
lines(X_grid, y_population, col = "red", lwd = 4)

# Add a legend
legend("topleft", legend = c("conditional", "population", "individuals"),
       col = c("black", "red", "grey"), lty = c(1, 1, 1), lwd = c(4, 4, 1))

# dev.off()

```

## Mixed Linear Model with Time-Varying Endogenous Covariate

Laten we nu een ingewikkelder voorbeeld beschouwen van een MLM uit sectie 2.2 van Qian et al. (2020) inclusief een time-varying covariaat $X_{it}$. In dit geval wordt elk individu op 2 tijdspunten geobserveerd ($T_i = 2$), en de covariaat op het tweede tijdspunt is de lag-1 uitkomst: $X_{i2} = Y_{i2}$.

> Door de uitkomst te laggen, hebben we in wezen drie tijdspunten: $X_{i1}$, $X_{i2} = Y_{i2}$, en $Y_{i3}$.

Stel dat de variabelen worden gegenereerd volgens het volgende multilevel lineaire model (MLM) met een random intercept:

$$
b_i \sim N(0, \sigma_b^2),
$$

$$
X_{i1} \sim N(0, \sigma_{X_1}^2) \text{ independently of } b_i,
$$

$$
Y_{i2} \mid X_{i1}, b_i \sim N(\beta_0 + \beta_1 X_{i1} + b_i, \sigma_\epsilon^2),
$$

$$
X_{i2} = Y_{i2},
$$

$$
Y_{i3} \mid X_{i1}, Y_{i2}, X_{i2}, b_i \sim N(\beta_0 + \beta_1 X_{i2} + b_i, \sigma_\epsilon^2).
$$

Dit impliceert the conditionele relatie

$$
E[Y_{it+1} \mid X_{it}] = \beta_0 + \beta_1 X_{i1} + b_i.
$$

terwijl de marginale relatie ingewikkelder is

$$
E[Y_{i2} \mid X_{i1}] = \beta_0 + \beta_1 X_{i1}.
$$

$$
E[Y_{i3} \mid X_{i2}] = (1-\rho \zeta - \rho) \beta_0 + [(1-\rho\zeta) \beta_1+\rho] X_{i2}.
$$

waar $\rho = \frac{\sigma_b^2}{\sigma_b^2 + \sigma_\epsilon^2}$ en $\zeta = \frac{\beta_1 \sigma_{X_1}^2}{\beta_1 \sigma_{X_1}^2 + \sigma_b^2 + \sigma_\epsilon^2}$. Laten we nu weer data simuleren en zowel de marginale als conditionele relaties tussen de covariaat $X_{it}$ en de uitkomstvariabele $Y_{it}$ onderzoeken. Maar we zetten sigma_epsilon op 0 zodat dit niet afleidt.

```{r}
#| label: Scenario2.2_DataGeneration
#| cache: true
#| eval: false
#| echo: false

set.seed(123)

# parameters
sigma_b = 3
# sigma_X1 = 1
# sigma_epsilon = 1
beta_0 = 0.8
beta_1 = 2

n_individuals = 20

# generate random intercepts
b0 = rnorm(n_individuals, mean = 0, sd = sigma_b)

X1_grid <- seq(-5, 5, length.out = 10000) # Values for X_it
X1 <- rnorm(n_individuals, mean = 0, sd = 1) # Values for X_i1

# Conditional-level 
expected_X2_conditional <- expected_Y2_conditional <- beta_0 + beta_1 * X1_grid + 0
expected_Y3_conditional <- beta_0 + beta_1 * expected_X2_conditional + 0

# Individual-specific 
expected_X2_individuals <- expected_Y2_individuals <- sapply(b0, function(b) beta_0 + beta_1 * X1_grid + b)
expected_Y3_individuals <- sapply(b0, function(b) beta_0 + beta_1 * expected_X2_conditional + b)

# Population-level
expected_X2_population <- expected_Y2_population <- rowMeans(expected_Y2_individuals) # method 1
expected_Y3_population <- rowMeans(expected_Y3_individuals) # method 1

### Plot Y2 against X1

par(mfrow = c(1, 2))

# plot the conditional-level curve
plot(X1_grid, expected_Y2_conditional, type = "l", lwd = 4, col = "black",
     ylim = c(-5, 5), xlim = c(-5, 5), xlab = expression(X[i1]), ylab = expression(Y[i2]),
     main = "Population, Conditional and Individual Logit Curves")

# add individual curves (grey lines)
for (i in 1:n_individuals) {
  lines(X1_grid, expected_Y2_individuals[, i], col = "grey", lwd = 1)
}

# add the population-level curve (red line)
lines(X1_grid, expected_Y2_population, col = "red", lwd = 4)

# add a legend
legend("topleft", legend = c("conditional", "population", "individuals"),
       col = c("black", "red",  "grey"), lty = c(1, 1, 1), lwd = c(4, 4, 1))


### Plot Y3 against X2

# plot the conditional-level curve
plot(expected_X2_conditional, expected_Y3_conditional, type = "l", lwd = 4, col = "black",
     ylim = c(-5, 5), xlim = c(-5, 5), xlab = expression(X[i2]), ylab = expression(Y[i3]),
     main = "Population, Conditional and Individual Logit Curves")

# add individual curves (grey lines)
for (i in 1:n_individuals) {
  lines(expected_X2_conditional, expected_Y3_individuals[, i], col = "grey", lwd = 1)
}

# add the population-level curve (red line)
lines(expected_X2_conditional, expected_Y3_population, col = "red", lwd = 4)

# add a legend
legend("topleft", legend = c("conditional", "population", "individuals"),
       col = c("black", "red",  "grey"), lty = c(1, 1, 1), lwd = c(4, 4, 1))
```

Let's now simulate data from this model and directly infer the relationships between the continuous covariate $X_{it}$ and the outcome variable $Y_{it}$.

```{r}
#| label: fig-mlm-time-varying-covariate
#| fig-cap: "True conditional effect and estimated marginal effects for 10,000 simulated individuals in a situation with a time-varying endogenous covariate in a mixed linear model."
#| cache: true
#| eval: false
#| echo: false
#| fig.width: 10
#| fig.height: 6


### Data Generation 

set.seed(123)

# parameters
sigma_b = 3
sigma_X1 = 1
# sigma_epsilon = 1 # let's exclude this for now
beta_0 = 0.8
beta_1 = 2

n_individuals = 100000

# generate random intercepts
simdata <- data.frame(b0 = rnorm(n_individuals, mean = 0, sd = sigma_b),
                      X1 = rnorm(n_individuals, mean = 0, sd = sigma_X1),
                      X2 = rep(NA, n_individuals),
                      Y2 = rep(NA, n_individuals),
                      Y3 = rep(NA, n_individuals))

# create a loop to compute the expected values for each individual
for (i in 1:n_individuals) {
  simdata$X2[i] <- simdata$Y2[i] <- beta_0 + beta_1 * simdata$X1[i] + simdata$b0[i]
  simdata$Y3[i] <- beta_0 + beta_1 * simdata$X2[i] + simdata$b0[i]
}

### Compute Marginal and Conditional Effects

# compute rho and zeta
rho = sigma_b^2 / (sigma_b^2 + sigma_epsilon^2) # should be 1, since sigma_epsilon = 0
zeta = beta_1 * sigma_X1^2 / (beta_1 * sigma_X1^2 + sigma_b^2 + sigma_epsilon^2)

# compute marginal effect
marginal_intercept_x1_y2 = beta_0
marginal_slope_x1_y2 = beta_1

marginal_intercept_x2_y3 = (1 - rho * zeta - rho) * beta_0
marginal_slope_x2_y3 = (1 - rho * zeta) * beta_1 + rho

### Estimate Marginal Effects
# Let's confirm if we can use the formulas supplied in Qian et al. (2020) 
# to retrieve the true marginal effect

lm_y2_x1 <- lm(simdata$Y2 ~ simdata$X1)$coef
lm_y3_x2 <- lm(simdata$Y3 ~ simdata$X2)$coef

### Plot Marginal and Conditional Effects

# compute expected value of b0i given Xit

png("figure/fig-mlm-time-varying-covariate.png", res = 300, width = 4000, height = 2000)

par(mfrow = c(1, 2))
plot(simdata$X1, simdata$Y2, col = "blue", pch = 16, cex = 0, xlab = expression(X[i1]), ylab = expression(Y[i2]))
abline(a = beta_0, b = beta_1, col = "blue", lty = 1, lwd = 2)
abline(reg = lm_y2_x1, col = "red", lty = 2, , lwd = 2) 
abline(a = marginal_intercept_x1_y2, b = marginal_slope_x1_y2, col = "red", lty = 1, lwd = 2)

legend("topleft", legend = c("true marginal effect", "estimated marginal effect", "true conditional effect"),
       col = c("blue", "red", "red"), lty = c(1, 2, 1), lwd = c(2, 2, 2))

plot(simdata$X2, simdata$Y3, col = "blue", pch = 16, cex = 0, xlab = expression(X[i2]), ylab = expression(Y[i3]))
abline(a = beta_0, b = beta_1, col = "blue", lty = 1, lwd = 2)
abline(reg = lm_y3_x2, col = "red", lty = 2, , lwd = 2) 
abline(a = marginal_intercept_x2_y3, b = marginal_slope_x2_y3, col = "red", lty = 1, lwd = 2)

legend("topleft", legend = c("true marginal effect", "estimated marginal effect", "true conditional effect"),
       col = c("blue", "red", "red"), lty = c(1, 2, 1), lwd = c(2, 2, 2))

dev.off()

### create table with overview of results
results <- data.frame(
  row.names = c("intercept X1 Y2", "slope X1 Y2", "intercept X2 Y3", "slope X2 Y3"),
  conditional_effect = c(beta_0, beta_1, beta_0, beta_1),
  true_marginal_effect = c(marginal_intercept_x1_y2, marginal_slope_x1_y2, marginal_intercept_x2_y3, marginal_slope_x2_y3),
  estimated_marginal_effect = c(lm_y2_x1[1], lm_y2_x1[2], lm_y3_x2[1], lm_y3_x2[2])
)

saveRDS(results, "simulation_scenarios/output/summary_section2.2_results.rds")
```

```{r}
results <- readRDS("simulation_scenarios/output/summary_section2.2_results.rds")
knitr::kable(results, caption = "Summary of the true conditional and estimated marginal effects for the simulated data (N = 100,000).")
```

![True conditional effect and estimated/true marginal effects for 100,000 simulated individuals in a situation with a time-varying endogenous covariate in a mixed linear model.](images/fig-mlm-time-varying-covariate.png){#fig-simulationresultssection2.2}

Let us now create a second plot in which the effects of X1 on Y2 and X2 on Y3 are shown in the same plot.

```{r}
#| label: Scenario2.2_MarginalEffect

png("figure/fig-mlm-time-varying-covariate-together.png", res = 300, width = 2000, height = 2000)

# create empty plot
plot(1, type = "n", xlim = c(-5, 6), ylim = c(-5, 10), xlab = "", ylab = "", main = "Marginal Effects")

# now add the marginal effects
abline(a = beta_0, b = beta_1, col = "blue", lty = 1, lwd = 2) # true conditional effect X1 Y2

abline(a = marginal_intercept_x1_y2, b = marginal_slope_x1_y2, col = "red", lwd = 2) # true marginal effect X1 Y2
abline(lm(simdata$Y2 ~ simdata$X1), col = "red", lty = 2) # estimated marginal effect X1 Y2
abline(a = marginal_intercept_x2_y3, b = marginal_slope_x2_y3, col = "orange", lwd = 2) # true marginal effect X2 Y3
abline(lm(simdata$Y3 ~ simdata$X2), col = "orange", lty = 2) # estimated marginal effect X2 Y3

legend("topleft", legend = c("true conditional effect X1 Y2", "true marginal effect X1 Y2", "estimated marginal effect X1 Y2", "true marginal effect X2 Y3", "estimated marginal effect X2 Y3"),
       col = c("blue", "red", "red", "orange", "orange"), lty = c(1, 1, 2, 1, 2), lwd = c(2, 2, 2, 2, 2))

dev.off()
```

![True conditional effect and estimated/true marginal effects for 100,000 simulated individuals in one plot.](images/fig-mlm-time-varying-covariate-together.png){#fig-simulationresultssection2.2-together}
