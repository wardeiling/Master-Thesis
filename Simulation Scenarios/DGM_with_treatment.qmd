---
title: "DGMs of Qian et al. (2020) - Part 2: With Treatment"
author: "Ward B. Eiling"
date: "2024-10-31"
date-modified: last-modified
format: 
  html:
    toc: true
    toc-location: left
    toc-depth: 3
    toc-expand: 3
    number-sections: true
    # embed-resources: false
  pdf:
    fig-pos: 'h'
  #   toc: true
  #   toc-depth: 5
  #   number-sections: true
  #   # embed-resources: true
  #   # default-image-extension: svg
execute:
  message: false
  warning: false
fig-cap-location: top
---

```{r}
#| label: Packages
#| echo: false

# for general data manipulation and plotting
library(tidyverse)
# for estimation
library(lme4)
library(gee)
library(geex)
library(geepack)
library(nlme)
# for presentation of results
library(jtools)
# for diagrams
library(dagitty)
library(ggdag)
library(DiagrammeR)
library(magick)
library(pdftools)
```

## Explanation versus Prediction

In het voorbeeld van Diggle et al. (2002) wat we vorige week hebben besproken, werd vermeld dat een cross-sectionele relatie tussen $X_{it}$ en $Y_{it}$ van interesse kan zijn met longitudinale data als voorspellen het doel is:

> "In many applications the cross-sectional association between Xit and Yit is of substantive interest. For example, in assessing the predictive potential of biomarkers for the detection of cancer, the accuracy of a marker is typically characterized by the cross-sectional sensitivity and specificity. Although alternative predictive models may be developed using longitudinal marker series, these models would not apply to the common clinical setting where only a single measurement is available." (Diggle et al., 2002, p. 256)

Daarentegen legt Qian et al. (2020) juist de nadruk op de voordelen van mixed linear models om tegelijkertijd ook individuele verschillen te kunnen voorspellen, waarbij de focus meer ligt op causaliteit:

> "A particularly appealing feature of random effects models is the ability to predict person-specific random effects, which enables quantitative characterization of between person heterogeneity due to unobserved factors (Schwartz and Stone, 2007, Bolger and Laurenceau, 2013). Understanding such heterogeneity can bring forth new scientific hypotheses for further studies. In addition, the random effects provide a model for the within-person dependence in the time-varying outcome, which improves efficiency in parameter estimation." (Qian et al., 2020, p. 376)

## Main Simulation of Qian et al. (2020): With Treatment

### Original Section: "4. Simulation"

In the simulation, we considered three generative models (GMs), all of which have an endogenous covariate. In the first two GMs, the endogenous covariate $X_{it}$ equals the previous outcome $Y_{it}$ plus some random noise, so the conditional independence assumption (10) is valid. In GM 3, the endogenous covariate depends directly on $b_i$, violating assumption (10). The details of the generative models are described below.

In GM1, we considered a simple case with only a random intercept and a random slope for $A_{it}$, so that $Z_{i(t_0)} = Z_{i(t_2)} = 1$ in model (7). The outcome is generated as:

$$
Y_{it+1} = \alpha_0 + \alpha_1 X_{it} + b_{i0} + A_{it} (\beta_0 + \beta_1 X_{it} + b_{i2}) + \epsilon_{it+1}.
$$

The random effects $b_{i0} \sim N(0, \sigma_{b0}^2)$ and $b_{i2} \sim N(0, \sigma_{b2}^2)$ are independent of each other. The covariate is generated as $X_{i1} \sim N(0, 1)$, and for $t \geq 2$,

$$
X_{it} = Y_{it} + N(0, 1).
$$

The randomization probability $p_t$ is constant at $1/2$. The exogenous noise is $\epsilon_{it+1} \sim N(0, \sigma_\epsilon^2)$.

In GM2, we considered the case where $Z_{i(t_0)} = Z_{i(t_2)} = 1$, with time-varying randomization probability. The outcome is generated as:

$$
Y_{it+1} = \alpha_0 + \alpha_1 X_{it} + b_{i0} + b_{i1} X_{it} + A_{it} (\beta_0 + \beta_1 X_{it} + b_{i2} + b_{i3} X_{it}) + \epsilon_{it+1}.
$$

The random effects $b_{ij} \sim N(0, \sigma_{b_j}^2)$, for $0 \leq j \leq 3$, are independent of each other. The covariate is generated as $X_{i1} \sim N(0, 1)$, and for $t \geq 2$,

$$
X_{it} = Y_{it} + N(0, 1).
$$

The randomization probability depends on $X_{it}$:

$$
p_t = 0.7 \cdot 1(X_{it} > -1.27) + 0.3 \cdot 1(X_{it} \leq -1.27),
$$

where $1(\cdot)$ represents the indicator function, and the cutoff $-1.27$ was chosen so that $p_t$ equals 0.7 or 0.3 for about half of the time. The exogenous noise is $\epsilon_{it+1} \sim N(0, \sigma_\epsilon^2)$.

GM3 is the same as GM 1, except that the covariate $X_{it}$ depends directly on $b_i$:

$$
X_{i1} \sim N(b_{i0}, 1), \quad X_{it} = Y_{it} + N(b_{i0}, 1) \text{ for } t \geq 2.
$$

We chose the following parameter values:

$$
\alpha_0 = -2, \quad \alpha_1 = -0.3, \quad \beta_0 = 1, \quad \beta_1 = 0.3,
$$

$$
\sigma_{b0}^2 = 4, \quad \sigma_{b1}^2 = \frac{1}{4}, \quad \sigma_{b2}^2 = 1, \quad \sigma_{b3}^2 = \frac{1}{4}, \quad \sigma_\epsilon^2 = 1.
$$

## Generative Model 1

### Translation of Notation

In the table below, we will provide the translation of original notation in Qian et al. (2020) to notation more common in psychological research

| Parameter                                     | Qian et al. (2020) | Raudenbusch and Bryk (2002) |
|----------------------------|----------------------|----------------------|
| Covariate                                     | $X_{it}$           | $Z_{it}$                    |
| Randomized Treatment                          | $A_{it}$           | $X_{it}$                    |
| Fixed intercept                               | $\alpha_0$         | $\gamma_{00}$               |
| Fixed slope for covariate                     | $\alpha_1$         | $\beta_{2}$                 |
| Random intercept                              | $b_{i0}$           | $u_{0i}$                    |
| Fixed effect of treatment                     | $\beta_0$          | $\gamma_{10}$               |
| Interaction effect of covariate and treatment | $\beta_1$          | $\beta_3$                   |
| Random slope for treatment                    | $b_{i2}$           | $u_{1i}$                    |
| Error term                                    | $\epsilon_{it+1}$  | $e_{it+1}$                  |

Let's first state the original model:

$$
Y_{it+1} = \alpha_0 + \alpha_1 X_{it} + b_{i0} + A_{it} (\beta_0 + \beta_1 X_{it} + b_{i2}) + \epsilon_{it+1}.
$$

Using this new notation, we may thus rewrite GM1 as a within-person (level 2) model:

$$
Y_{it+1} = \beta_{0i} + \beta_{1i} X_{it} + \beta_2 Z_{it} + \beta_3 Z_{it} X_{it} + e_{it+1},
$$

with the between-person (level 1) equations

$$ 
\beta_{0i} = \gamma_{00} + u_{0i} \quad \text{with} \quad u_{0i} \sim \mathcal{N}(0, \sigma^2_{u0}),
$$

$$ 
\beta_{1i} = \gamma_{10} + u_{1i} \quad \text{with} \quad u_{1i} \sim \mathcal{N}(0, \sigma^2_{u2}).
$$

Combining these two equations, the model can be expressed as:

$$
Y_{it+1} = \beta_{0i} + \beta_{1i} X_{it} + \beta_2 Z_{it} + \beta_3 Z_{it} X_{it} + e_{it+1} \\ = \gamma_{00} + u_{0i} + X_{it} (\gamma_{10} + u_{1i}) + \beta_2 Z_{it} + \beta_3 Z_{it} X_{it} + e_{it+1} \\ = \gamma_{00} + \beta_2 Z_{it} + u_{0i} + X_{it} (\gamma_{10} + \beta_3 Z_{it} + u_{1i}) + e_{it+1}
$$

More specifically, the process was generated as follows:

-   the random effects $u_{0i} \sim \mathcal{N}(0, 4)$ and $u_{1i} \sim \mathcal{N}(0, 1)$ are independent of each other
-   the covariate $Z_{i1} \sim \mathcal{N}(0, 1)$, and for $t \geq 2$, $Z_{it} = Y_{it} + \mathcal{N}(0, 1)$
-   the randomization probability $p_i = P(A_{it} = 1 \mid H_{it}) = 0.5$ and $A_{it} \sim \mathcal{Binomial}(n_{i}, p_{i} = 0.5)$
-   the exogenous noise $e_{it+1} \sim \mathcal{N}(0, 1)$
-   the parameter values are $\gamma_{00} = -2$, $\beta_{2} = -0.3$, $\gamma_{10} = 1$, $\beta_{3} = 0.3$

### Visualzing the Model

As mentioned by Ellen in the last meeting (17-10):

> "Conventional DAGs do not only represent main effects but rather the combination of main effects and interactions. Once you have drawn your DAG, you already assume that any variables pointing to the same outcome can modify the effect of the others pointing to the same outcome." ([stackexchange](https://stats.stackexchange.com/questions/157775/representing-interaction-effects-in-directed-acyclic-graphs))

So the DAG for the first couple observations, the DAG looks like

```{r}
#| label: fig-GM1_visual3
#| fig-cap: "DAG for Generative Model 1"
#| echo: false
#| eval: false

GM1_DAG3 <- dagitty('dag {
bb="0,0,1,1"
X_1 [exposure,pos="0.173,0.282"]
X_2 [exposure,pos="0.426,0.283"]
Y_2 [outcome,pos="0.422,0.431"]
Y_3 [outcome,pos="0.723,0.432"]
Z_1 [adjusted,pos="0.171,0.602"]
Z_2 [adjusted,pos="0.424,0.602"]
Z_3 [adjusted,pos="0.721,0.602"]
u0 [pos="0.549,0.783"]
u2 [pos="0.616,0.783"]
X_1 -> Y_2
X_2 -> Y_3
Y_2 -> Z_2
Y_3 -> Z_3
Z_1 -> Y_2
Z_2 -> Y_3
u0 -> Y_2
u0 -> Y_3
u2 -> Y_2
u2 -> Y_3
}')

ggdag::ggdag_status(GM1_DAG3) + ggdag::theme_dag()
```

![DAG for Generative Model 1](figure/GM1_DAG.png)

The red arrows here show the biased paths after controlling for the covariate $Z_{it}$.

Or we can display it as a path diagram, where parameter values are displayed and moderation is shown by the dashed arrow.

```{r}
#| label: fig-GM1_path
#| engine: 'tikz'
#| echo: false
#| cache: true
#| fig-cap: "Path diagram for Generative Model 1"

\begin{tikzpicture}
  % Nodes for observed variables (squares)
  \node[draw, rectangle] (Z1) at (0, -2) {$Z_{1i}$};
  \node[draw, rectangle] (X1) at (0, 2) {$X_{1i}$};
  \node[draw, rectangle] (Y2) at (3, 0) {$Y_{2i}$}; % Increased x-coordinate
  \node[draw, rectangle] (Z2) at (3, -2) {$Z_{2i}$}; % Increased x-coordinate
  \node[draw, rectangle] (X2) at (3, 2) {$X_{2i}$}; % Increased x-coordinate
  \node[draw, rectangle] (Y3) at (6, 0) {$Y_{3i}$}; % Increased x-coordinate
  \node[draw, rectangle] (Z3) at (6, -2) {$Z_{3i}$}; % Increased x-coordinate

  % Nodes for latent variables (circles)
  \node[draw, circle] (u0) at (6, 4) {$u_{0i}$}; % Increased x-coordinate
  \node[draw, circle] (u2) at (3, 4) {$u_{2i}$}; % Adjusted to align with middle row

  % Arrows with path coefficients
  \draw [->] (u0) -- node[right] {$+$} (Y2);
  \draw [->] (u0) -- node[right] {$+$} (Y3);
  \draw [->] (X2) edge node[above] {$\gamma_{10}$} (Y3);
  \draw [->] (Z2) edge node[below] {$\gamma_{01}$} (Y3);
  \draw [->] (Y2) edge node[left] {$=$} (Z2);
  \draw [->] (X1) edge node[left] {$\gamma_{10}$} (Y2);
  \draw [->] (Z1) edge node[below] {$\gamma_{01}$} (Y2);
  \draw [->] (Y3) edge node[right] {$=$} (Z3);

  % Curved arrows for variances
  \draw [->, out=-45, in=-135, looseness=2] (Z1) to node[below] {$\sigma^2_{Z}$} (Z1);
  \draw [->, out=-45, in=-135, looseness=2] (Z2) to node[below] {$\sigma^2_{Z}$} (Z2);
  \draw [->, out=-45, in=-135, looseness=2] (Z3) to node[below] {$\sigma^2_{Z}$} (Z3);
  \draw [->, out=45, in=135, looseness=2] (u0) to node[above] {$\sigma^2_{u0}$} (u0);
  \draw [->, out=45, in=135, looseness=2] (u2) to node[above] {$\sigma^2_{u2}$} (u2);
  \draw [->, out=30, in=330, looseness=2] (Y2) to node[right] {$\sigma^2_{e}$} (Y2);
  \draw [->, out=30, in=330, looseness=2] (Y3) to node[right] {$\sigma^2_{e}$} (Y3);

  % Additional paths for Z and Y interaction effects
  \draw[->, dashed] (u2) -- (1.5,1); % Adjusted x-coordinates
  \draw[->, dashed] (u2) -- (4.5,1); % Adjusted x-coordinates
  \draw[->, dashed] (Z1) -- node[right] {$\gamma_{11}$} (1.5,1);
  \draw[->, dashed] (Z2) -- node[right] {$\gamma_{11}$} (4.5,1);

\end{tikzpicture}
```

<!-- ![Path diagram for Generative Model 1](fig-GM1_path-1.png) -->

We can make a couple observations from this path diagram:

-   Contrary to the DAG, this path diagram shows the moderation effect (1) of $Z_{it}$ on the relationship between $X_{it}$ and $Y_{it+1}$ and (2) of $u_{2i}$ on the relationship between $Z_{it}$ and $Y_{it+1}$.
-   Similar to the example without treatment in section 2.2, the covariate $Z_{it}$ is determined by the previous value of the outcome $Y_{it}$---which makes it an endogenous time-varying covariate.

### Data Generating and Estimation

The data generating process for this model is given by

$$
Y_{it+1} = \gamma_{00} + u_{0i} + X_{it} (\gamma_{10} + u_{1i}) + \beta_2 Z_{it} + \beta_3 Z_{it} X_{it} + e_{it+1}
$$

More specifically, the process was generated as follows:

-   $u_{0i} \sim \mathcal{N}(0, 4)$ and $u_{1i} \sim \mathcal{N}(0, 1)$ are independent of each other
-   $Z_{i1} \sim \mathcal{N}(0, 1)$, and for $t \geq 2$, $Z_{it} = Y_{it} + \mathcal{N}(0, 1)$
-   $p_i = P(A_{it} = 1 \mid H_{it}) = 0.5$ and $A_{it} \sim \mathcal{Binomial}(n_{i}, p_{i} = 0.5)$
-   $e_{it+1} \sim \mathcal{N}(0, 1)$
-   $\gamma_{00} = -2$, $\beta_{2} = -0.3$, $\gamma_{10} = 1$, $\beta_{3} = 0.3$

```{r}
#| label: GM1_datageneration
#| echo: true
#| eval: false
#| cache: true

dgm1 <- function(sample_size, total_T) {
    
    # Parameters
    gamma_00 <- -2   # Fixed intercept
    beta_2 <- -0.3 # Fixed slope for Z
    gamma_10 <- 0.5    # Fixed effect of treatment (X)
    beta_3 <- 0.3  # Interaction effect between treatment (X) and covariate (Z)
    sigma_u0 <- 2    # SD of random intercept (u_0i)
    sigma_u2 <- 1    # SD of random slope for treatment (u_1i)
    sigma_e <- 1     # SD of error term (e_{it+1})
    prob_x <- 0.5    # Randomization probability for treatment (X)
    
    # Data frame setup
    df_names <- c("userid", "day", "Z", "prob_X", "X", "Y", "u0", "u2", "e", "delta")
    dta <- data.frame(matrix(NA, nrow = sample_size * total_T, ncol = length(df_names)))
    names(dta) <- df_names

    # Assign userid and day
    dta$userid <- rep(1:sample_size, each = total_T)
    dta$day <- rep(1:total_T, times = sample_size)

    # Generate uncorrelated random effects
    u_0i <- rnorm(sample_size, mean = 0, sd = sigma_u0)
    u_1i <- rnorm(sample_size, mean = 0, sd = sigma_u2)

    # Data generation for each time point
    for (t in 1:total_T) {
        # Row index for day t for every subject
        row_index <- seq(from = t, by = total_T, length = sample_size)
        
        # Generate Z based on the process described
        if (t == 1) {
            dta$Z[row_index] <- rnorm(sample_size, mean = 0, sd = 1)
        } else {
            dta$Z[row_index] <- dta$Y[row_index_lag1] + rnorm(sample_size, mean = 0, sd = 1)
        }
        
        # Set fixed probability for treatment assignment
        dta$prob_X[row_index] <- rep(prob_x, sample_size)
        
        # Treatment assignment
        dta$X[row_index] <- rbinom(sample_size, 1, dta$prob_X[row_index])
        
        # Error term
        dta$e[row_index] <- rnorm(sample_size, mean = 0, sd = sigma_e)
        
        # compute part of the equation
        dta$delta[row_index] <- gamma_10 + beta_3 * dta$Z[row_index] + u_1i
        
        # Outcome Y
        dta$Y[row_index] <- gamma_00 + beta_2 * dta$Z[row_index] + u_0i + 
                            dta$X[row_index] * dta$delta[row_index] + dta$e[row_index]
        
        # Store random effects
        dta$u0[row_index] <- u_0i
        dta$u2[row_index] <- u_1i
        
        # Update row index for lagged Y
        row_index_lag1 <- row_index
    }
    
    return(dta)
}

# Run the data generation function
set.seed(123987)
data <- dgm1(sample_size = 100000, total_T = 10)
saveRDS(data, "Simulation Scenarios/data/Qian_GM1_data.rds")
```

```{r}
#| label: GM1_datageneration_qian

source("Scripts/Qian2020 Code/generative_model.R")
source("Scripts/DataGeneratingModels/GM1.R")

# Run the data generation function
set.seed(123987)
data <- dgm1(sample_size = 100000, total_T = 10)
data2 <- dgm_with_treatment(sample_size = 100000, total_T = 10, dgm_type = 1)
data3 <- GM1(sample_size = 100000, total_T = 10)

fit <- lmer(Y ~ Z * X + (1 + X | userid), data = data)
fit2 <- lmer(Y ~ X * A + (1 + A | userid), data = data2)
fit3 <- lmer(Y ~ X * A + (1 + A | userid), data = data3)

fixef(fit)
fixef(fit2)
fixef(fit3)
```

The analytical model for the mixed linear model is equivalent to the data generating model:

$$
Y_{it+1} = \gamma_{00} + u_{0i} + X_{it} (\gamma_{10} + u_{1i}) + \beta_2 Z_{it} + \beta_3 Z_{it} X_{it} + e_{it+1}
$$

However, for GEE, the analytical model does not include random coefficients, so reduces to:

$$
Y_{it+1} = \gamma_{00} + X_{it} \gamma_{10} + \beta_2 Z_{it} + \beta_3 Z_{it} X_{it} + e_{it+1}
$$

Considering this difference and the nonzero specification of the random effects, we expect that the fixed treatment effect, denoted by $gamma_10$, is not equal across the mixed linear model and its GEE counterparts.

```{r}
#| label: GM1_fit
#| cache: false
#| echo: true
#| eval: false

# load data
data <- readRDS("Simulation Scenarios/data/Qian_GM1_data.rds")

# Fit models
gee_indep <- geeglm(Y ~ Z + X + Z*X, id = userid, data = data, corstr = "independence")
gee_exch <- geeglm(Y ~ Z + X + Z*X, id = userid, data = data, corstr = "exchangeable")
gee_ar1 <- geeglm(Y ~ Z + X + Z*X, id = userid, data = data, corstr = "ar1")
mlm_mle <- lmer(Y ~ Z + X + Z*X + (1 + X | userid), data = data, REML = FALSE)

treatment_effect <- c(coef(gee_indep)["X"], coef(gee_exch)["X"], coef(gee_ar1)["X"], fixef(mlm_mle)["X"])
true_treatment_effect <- gamma_10 <- 1
interaction_effect <- c(coef(gee_indep)["Z:X"], coef(gee_exch)["Z:X"], coef(gee_ar1)["Z:X"], fixef(mlm_mle)["Z:X"])
true_interaction_effect <- beta_3 <- 0.3

df_results <- data.frame(row.names = c("GEE (Indep)", "GEE (Exch)", "GEE (AR1)", "MLM (MLE)"), treatment_estimate = treatment_effect, treatment_true = gamma_10, interaction_estimate = interaction_effect, interaction_true = true_interaction_effect)
saveRDS(df_results, "Simulation Scenarios/data/Qian_GM1_results.rds")
```

```{r}
#| label: GM1_results
#| echo: false

df_results <- readRDS("Simulation Scenarios/data/Qian_GM1_results.rds")
knitr::kable(df_results, digits = 3, caption = "Generating Model 1 - Treatment Effect Estimates")
```

<!-- ## Generative Model 2 -->

<!-- ### Translation of Notation -->

<!-- Now we need to translate more parameters: -->

<!-- | Parameter                                            | Original          | New           | -->

<!-- |------------------------------------|-------------------|-------------------| -->

<!-- | Fixed intercept                                      | $\alpha_0$        | $\gamma_{00}$ | -->

<!-- | Fixed slope for $X_{it}$                             | $\alpha_1$        | $\gamma_{10}$ | -->

<!-- | Random intercept                                     | $b_{i0}$          | $u_{0i}$      | -->

<!-- | Random slope for $X_{it}$                            | $b_{i1}$          | $u_{1i}$      | -->

<!-- | Fixed effect of $A_{it}$                             | $\beta_0$         | $\gamma_{20}$ | -->

<!-- | Interaction effect of $A_{it}$ and $X_{it}$          | $\beta_1$         | $\gamma_{30}$ | -->

<!-- | Random slope for $A_{it}$                            | $b_{i2}$          | $u_{2i}$      | -->

<!-- | Random interaction effect for $A_{it} \times X_{it}$ | $b_{i3}$          | $u_{3i}$      | -->

<!-- | Error term                                           | $\epsilon_{it+1}$ | $e_{it+1}$    | -->

<!-- | Covariate                                            | $X_{it}$          | $Z_{it}$      | -->

<!-- | Treatment                                            | $A_{it}$          | $X_{it}$      | -->

<!-- Let's first restate the original model: -->

<!-- $$ -->

<!-- Y_{it+1} = \alpha_0 + \alpha_1 X_{it} + b_{i0} + b_{i1} X_{it} + A_{it} (\beta_0 + \beta_1 X_{it} + b_{i2} + b_{i3} X_{it}) + \epsilon_{it+1}. -->

<!-- $$ -->

<!-- Using the psychological notation, we rewrite GM2 as a within-person model: -->

<!-- $$ -->

<!-- Y_{it+1} = \beta_{0i} + \beta_{1i} Z_{it} + \beta_{2i} X_{it} + \beta_{3i} X_{it} Z_{it} + e_{it+1}, -->

<!-- $$ -->

<!-- with: -->

<!-- $$ -->

<!-- \beta_{0i} = \gamma_{00} + u_{0i} \quad \text{where} \quad u_{0i} \sim \mathcal{N}(0, \sigma^2_{u0}), -->

<!-- $$ -->

<!-- $$ -->

<!-- \beta_{1i} = \gamma_{10} + u_{1i} \quad \text{where} \quad u_{1i} \sim \mathcal{N}(0, \sigma^2_{u1}), -->

<!-- $$ -->

<!-- $$ -->

<!-- \beta_{2i} = \gamma_{20} + u_{2i} \quad \text{where} \quad u_{2i} \sim \mathcal{N}(0, \sigma^2_{u2}), -->

<!-- $$ -->

<!-- $$ -->

<!-- \beta_{3i} = \gamma_{30} + u_{3i} \quad \text{where} \quad u_{3i} \sim \mathcal{N}(0, \sigma^2_{u3}). -->

<!-- $$ -->

<!-- Combining these, the full model becomes: -->

<!-- $$ -->

<!-- Y_{it+1} = (\gamma_{00} + u_{0i}) + (\gamma_{10} + u_{1i}) Z_{it} + (\gamma_{20} + u_{2i}) X_{it} + (\gamma_{30} + u_{3i}) X_{it} Z_{it} + e_{it+1}. -->

<!-- $$ -->

<!-- More specifically, the process was generated as follows: -->

<!-- -    -->

<!-- ### Visualizing the Model -->

<!-- ```{r} -->

<!-- # #| label: GM2_visual -->

<!-- # #| cache: true -->

<!-- # #| fig-subcap: -->

<!-- # #| - "DAG" -->

<!-- # #| - "Path Diagram" -->

<!-- # #| layout-nrow: 2 -->

<!-- # #| echo: false -->

<!-- #  -->

<!-- # # GM2_DAG <- dagitty('dag{ -->

<!-- ``` -->

<!-- The model is fitted as -->

<!-- ```{r} -->

<!-- #| label: GM2_fit -->

<!-- #| echo: true -->

<!-- #| eval: false -->

<!-- gm2_mlm <- lmer(Y ~ Z * X + (Z * X | id), data = data) -->

<!-- ``` -->

<!-- ## Generative Model 3 -->

<!-- ### Translation of Notation -->

<!-- ... -->

<!-- ### Visualizing the Model -->

<!-- ... -->
