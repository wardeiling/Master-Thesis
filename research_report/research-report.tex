% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  12pt,
  a4paper,
]{article}

\usepackage{amsmath,amssymb}
\usepackage{setspace}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
  \setmainfont[]{Latin Modern Roman}
  \setsansfont[]{Latin Modern Roman}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{xcolor}
\usepackage[top=2.5cm,bottom=2.5cm,left=2.5cm,right=2.5cm]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{fancyhdr}
\usepackage{amsmath}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Estimation of Effects of Endogenous Time-Varying Covariates: A Comparison Of Multilevel Linear Modeling and Generalized Estimating Equations},
  pdfauthor={Ward B. Eiling (9294163)},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}

\title{Estimation of Effects of Endogenous Time-Varying Covariates: A
Comparison Of Multilevel Linear Modeling and Generalized Estimating
Equations}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Research Report}
\author{Ward B. Eiling (9294163)}
\date{December 22, 2024}

\begin{document}
\cleardoublepage
\thispagestyle{empty}
{\centering
\hbox{}\vskip 0cm plus 1fill
% \vspace{25ex}
{\Large\bfseries Estimation of Effects of Endogenous Time-Varying
Covariates: A Comparison Of Multilevel Linear Modeling and Generalized
Estimating Equations \par}
\vspace{3ex}
{\large Research Report \par}
\vspace{9ex}
{\large\bfseries Ward B. Eiling (9294163) \par}
\vspace{3ex}
% {\Large ORCID: 0009-0007-8114-9497 \par}
% \vspace{3ex}
{\large Supervisors: Ellen Hamaker and Jeroen Mulder \par}
% \vskip 0cm plus 2fill
\vspace{9ex}
{\normalsize \textit{Master's degree in Methodology and Statistics for the Behavioural, \\ Biomedical and Social Sciences} \par}
\vspace{3ex}
{\normalsize \textit{Utrecht University} \par}
\vspace{9ex}
{\normalsize December 22, 2024 \par}
\vspace{3ex}
{\normalsize Word count: 728 \par}
\vspace{9ex}
{\normalsize FETC-approved: 24-2003 \par}
\vspace{9ex}
{\normalsize \textit{Candidate journal: Psychological Methods} \par}
\hbox{}\vskip 0cm plus 1fill
% \vspace{12ex}
% %
% %
% {\large Utrecht University \par}
% %
% %
% {\large Methodology and Statistics \par}
% \vspace{3ex}
% %
% {\large  \par}
% %
% \vspace{12ex}
% {\small Submitted in total fulfilment of the requirements
% of the degree of Doctor of Philosophy \par}
}

\setstretch{2}
\newpage

\section{Introduction}\label{introduction}

Across a wide range of disciplines, researchers analyze clustered
longitudinal, observational data to investigate prospective causal
relationships between variables. When analyzing such data, the
psychological sciences most commonly resort to the multilevel linear
model (MLM, \citeproc{ref-mcneish2017}{McNeish et al., 2017}),
which---in the context of longitudinal data analysis---separates
observed variance into stable between-person differences and
within-person fluctuations (\citeproc{ref-hamaker2020}{Hamaker \&
Muth√©n, 2020}). Conversely, other fields, such as biostatistics and
econometrics often favour generalized estimating equations (GEE) for the
analysis of longitudinal data (\citeproc{ref-mcneish2017}{McNeish et
al., 2017}). Despite some cross-disciplinary efforts to compare these
methods (\citeproc{ref-mcneish2017}{McNeish et al., 2017};
\citeproc{ref-muth2016}{Muth et al., 2016}; \citeproc{ref-yan2013}{Yan
et al., 2013}), their scarcity may leave researchers with limited
guidance in choosing the most suitable approach for their application.

A recent study by Qian et al. (\citeproc{ref-qian2020}{2020})
highlighted an issue present in both methods---except for GEE with
working independence---where controlling for \emph{time-varying
endogenous covariates} may lead to biased causal estimates. A
time-varying covariate is \emph{endogenous} if it is directly or
indirectly influenced by prior treatment or outcome, meaning its value
may be determined by earlier stages of the process
(\citeproc{ref-qian2020}{Qian et al., 2020}). As a result of including
these covariates in these models, ordinary interpretations of the
coefficients are no longer valid (\citeproc{ref-qian2020}{Qian et al.,
2020, p. 3}). According to Diggle (\citeproc{ref-diggle2002}{2002}),
this issue not only pertains GEE and MLM, but \emph{all} longitudinal
data analysis methods.

However, due to a divide between the disciplines that employ these
methods, such critiques of the MLM appear to have largely failed to
reach the applied researcher in psychology. One specific reason might be
that the technical jargon in other disciplines makes it difficult for
researchers to recognize when and how these issues emerge\footnote{For
  instance, the term `endogeneity' in econometrics, while related, has a
  distinct meaning from that of an endogenous variable, which can lead
  to confusion.}. Therefore, this report aims to understand and explain
the issue of including endogenous covariates in analyses involving GEE
and MLM in a psychological context. To achieve this aim, the current
investigation will employ (a) graphical tools such as the directed
acyclic graph (DAG) and path diagram to assess causal identification
assumptions, as well as (b) simulations with additional scenarios to
pinpoint the issue.

Accordingly, the following research questions will be addressed with
sub-questions being specified to isolate the issue described in the Qian
et al. (\citeproc{ref-qian2020}{2020}):

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\item
  When does the inclusion of endogenous variables in multilevel linear
  models result in biased estimates of the treatment effect?

  \begin{enumerate}
  \def\labelenumii{(\alph{enumii})}
  \item
    How is the bias in the treatment effect affected by the removal of
    the interaction \(\beta_1\) from generative model 3?
  \item
    How is the bias in the treatment effect affected by the removal of
    the random slope \(b_{i2}\) from generative model 3?
  \end{enumerate}
\item
  When does the inclusion of of endogenous covariates in multilevel
  linear models result in a discrepancy between conditional and marginal
  interpretations of the treatment effect?
\end{enumerate}

Research questions 1 and 2 will be investigated by employing MLM and GEE
estimation respectively.

\newpage

\section{Methods}\label{methods}

To obtain a better understanding of the issue exposed by Qian et al.
(\citeproc{ref-qian2020}{2020}), two methods were employed. First,
graphical methods were used provide insight into the presence and extent
of bias with potential violation of assumptions: (a) path diagrams were
used to evaluate the conditional independence assumption and (b)
directed acyclic graphs (DAGs) were used to evaluate the backdoor
criterion (Pearl, 1988, 2009). Second, a simulation study was performed
to reproduce the results for the generative models (GMs) from Qian et
al. (\citeproc{ref-qian2020}{2020}) and to further isolate the issue
using additional GMs.

\subsection{Data Generation}\label{data-generation}

In the simulation Qian et al. (\citeproc{ref-qian2020}{2020}) considered
three generative models (GMs), all of which have an endogenous
time-varying covariate. In GM1 and GM2, the endogenous covariate
\(X_{it}\) equals the previous outcome \(Y_{it}\) plus some random
noise, so the \emph{conditional independence} assumption is valid. In
GM3, the endogenous covariate depends directly on \(b_{i0}\), violating
the assumption. To isolate the issue in GM3, we consider two variations
on this model: GM3A, where the random slope \(b_{i2}\) for the treatment
\(A_{it}\) is removed; GM3B, where the interaction term
\(\beta_1 A_{it} X_{it}\) is removed. Note that the conditional
independence assumption is violated in either of these variations. The
details of the generative models are described below. We follow the
notation of Qian et al. (\citeproc{ref-qian2020}{2020}) to allow for
direct comparison, but rewrite the equations into within- and
between-person models (see \citeproc{ref-raudenbush2002}{Raudenbush \&
Bryk, 2002}). We accompany the equations of the GMs with graphical
representations, where random effects are represented by grey circles,
observed variables by squares and relationships across variables by
arrows. The path diagrams of the three data generating models shows the
discrepancies between the different generative models---especially
concerning the interaction effects---more clearly than DAGs.

\subsubsection{Generative Model 1}\label{generative-model-1}

In GM1, we considered a simple case with only a random intercept and a
random slope for \(X_{it}\). The outcome is generated according to the
following repeated-observations or within-person model (level 1):

\[
Y_{it+1} = \pi_{0i} + \pi_{1i} X_{it} + \pi_{2i} A_{it} + \pi_{3i} A_{it} X_{it} + \epsilon_{it+1}
\]

with the person-level or between-person model (level 2):

\[
\pi_{0i} = \alpha_0 + b_{i0}, \quad b_{i0} \sim \mathcal{N}(0, \sigma_{b0}^2),
\]

\[
\pi_{1i} = \alpha_1,
\]

\[
\pi_{2i} = \beta_0 + b_{i2}, \quad b_{i2} \sim \mathcal{N}(0, \sigma_{b2}^2),
\]

\[
\pi_{3i} = \beta_1.
\]

By substitution, we get the single equation model:

\[
\begin{aligned}
Y_{it+1} &= \pi_{0i} + \pi_{1i} X_{it} + \pi_{2i} A_{it} + \pi_{3i} A_{it} X_{it} + \epsilon_{it+1} \\
&= (\alpha_0 + b_{i0}) + \alpha_1 X_{it} + (\beta_0 + b_{i2}) A_{it} + \beta_1 A_{it} X_{it} + \epsilon_{it+1} \\
&= \alpha_0 + \alpha_1 X_{it} + b_{i0} + A_{it} (\beta_0 + \beta_1 X_{it} + b_{i2}) + \epsilon_{it+1}.
\end{aligned}
\]

The random effects \(b_{i0} \sim \mathcal{N}(0, \sigma_{b0}^2)\) and
\(b_{i2} \sim \mathcal{N}(0, \sigma_{b2}^2)\) are independent of each
other. The covariate is generated as \(X_{i1} \sim \mathcal{N}(0, 1)\),
and for \(t \geq 2\),

\[
X_{it} = Y_{it} + \mathcal{N}(0, 1).
\]

The randomization probability \(p_t = P(A_{it} = 1 \mid H_{it})\) is
constant at \(1/2\). Thus, \(A_{it} \sim \text{Bernoulli}(0.5)\) for
\(i = 1, \ldots, N\) and \(t = 1, \ldots, T\). The exogenous noise is
\(\epsilon_{it+1} \sim \mathcal{N}(0, \sigma_\epsilon^2)\).

Figure~\ref{fig-GM1_path} shows the path diagram for GM1.

\begin{figure}[H]

\caption{\label{fig-GM1_path}Path diagram for Generative Model 1
(\(t = 1, 2, 3\))}

\centering{

\includegraphics{research-report_files/figure-pdf/fig-GM1_path-1.pdf}

}

\end{figure}%

\subsubsection{Generative Model 2}\label{generative-model-2}

In GM2, we considered the case with a random intercept and random slopes
for (1) covariate \(X_{it}\), (2) treatment \(A_{it}\), and (3) the
interaction between \(A_{it}\) and \(X_{it}\); and with a time-varying
randomization probability for treatment. The outcome is generated
according to the same repeated-observations model presented in GM1.
However, the person-level model is different:

\[
\pi_{0i} = \alpha_0 + b_{i0}, \quad b_{i0} \sim \mathcal{N}(0, \sigma_{b0}^2),
\]

\[
\pi_{1i} = \alpha_1 + b_{i1}, \quad b_{i1} \sim \mathcal{N}(0, \sigma_{b1}^2),
\]

\[
\pi_{2i} = \beta_0 + b_{i2}, \quad b_{i2} \sim \mathcal{N}(0, \sigma_{b2}^2),
\]

\[
\pi_{3i} = \beta_1 + b_{i3}, \quad b_{i3} \sim \mathcal{N}(0, \sigma_{b3}^2).
\]

By substitution, we get the single equation model:

\[
\begin{aligned}
Y_{it+1} &= \pi_{0i} + \pi_{1i} X_{it} + \pi_{2i} A_{it} + \pi_{3i} A_{it} X_{it} + \epsilon_{it+1} \\ 
&= (\alpha_0 + b_{i0}) + (\alpha_1 + b_{i1}) X_{it} + (\beta_0 + b_{i2}) A_{it} + (\beta_1 + b_{i3}) A_{it} X_{it} + \epsilon_{it+1} \\ 
&= \alpha_0 + \alpha_1 X_{it} + b_{i0} + b_{i1} X_{it} + A_{it} \left( \beta_0 + \beta_1 X_{it} + b_{i2} + b_{i3} X_{it} \right) + \epsilon_{it+1}.
\end{aligned}
\]

The random effects \(b_{ij} \sim \mathcal{N}(0, \sigma_{bj}^2)\), for
\(j = 0, 1, 2, 3\), are independent of each other. The covariate is
generated as \(X_{i1} \sim \mathcal{N}(0, 1)\), and for \(t \geq 2\),

\[
X_{it} = Y_{it} + \mathcal{N}(0, 1).
\]

The randomization probability depends on \(X_{it}\):

\[
p_t = P(A_{it} = 1 \mid H_{it}) = 
\begin{cases} 
0.7 & \text{if } X_{it} > -1.27, \\
0.3 & \text{if } X_{it} \leq -1.27,
\end{cases}
\]

where the cutoff \(-1.27\) was chosen so that \(p_t\) equals 0.7 or 0.3
for about half of the time. In other words, if the value of the
covariate for any given person and time point is above the cutoff, the
probability of receiving the treatment \(p_t\) is 0.7; otherwise, it is
0.3. Accordingly, \(A_{it} \sim \text{Bernoulli}(p_t)\) for
\(i = 1, \ldots, N\) and \(t = 1, \ldots, T\). The exogenous noise is
\(\epsilon_{it+1} \sim \mathcal{N}(0, \sigma_\epsilon^2)\).

Figure~\ref{fig-GM2_path} shows the path diagram for GM2.

\begin{figure}[H]

\caption{\label{fig-GM2_path}Path diagram for Generative Model 2
(\(t = 1, 2, 3\))}

\centering{

\includegraphics{research-report_files/figure-pdf/fig-GM2_path-1.pdf}

}

\end{figure}%

\subsubsection{Generative Model 3}\label{generative-model-3}

GM3 is the same as GM1, except that the covariate \(X_{it}\) depends
directly on \(b_{i0}\):

\[
X_{i1} \sim \mathcal{N}(b_{i0}, 1), \quad X_{it} = Y_{it} + \mathcal{N}(b_{i0}, 1) \text{ for } t \geq 2.
\]

Figure~\ref{fig-GM3_path} shows the path diagram for GM3.

\begin{figure}[H]

\caption{\label{fig-GM3_path}Path diagram for Generative Model 3
(\(t = 1, 2, 3\))}

\centering{

\includegraphics{research-report_files/figure-pdf/fig-GM3_path-1.pdf}

}

\end{figure}%

\subsubsection{Generative Model 3A}\label{generative-model-3a}

GM3A is the same as GM3, except that the random slope \(b_{i2}\) for the
treatment \(A_{it}\) is removed. The single equation model then becomes:

\[
Y_{it+1} = \alpha_0 + \alpha_1 X_{it} + b_{i0} + A_{it} (\beta_0 + \beta_1 X_{it}) + \epsilon_{it+1}.
\]

\begin{figure}[H]

\caption{\label{fig-GM3A_path}Path diagram for Generative Model 3A
(\(t = 1, 2, 3\))}

\centering{

\includegraphics{research-report_files/figure-pdf/fig-GM3A_path-1.pdf}

}

\end{figure}%

\subsubsection{Generative Model 3B}\label{generative-model-3b}

GM3B is the same as GM3, except that the interaction term
\(\beta_1 A_{it} X_{it}\) is removed. The single equation model then
becomes:

\[
Y_{it+1} = \alpha_0 + \alpha_1 X_{it} + b_{i0} + A_{it} (\beta_0 + b_{i2}) + \epsilon_{it+1}.
\]

\begin{figure}[H]

\caption{\label{fig-GM3B_path}Path diagram for Generative Model 3B
(\(t = 1, 2, 3\))}

\centering{

\includegraphics{research-report_files/figure-pdf/fig-GM3B_path-1.pdf}

}

\end{figure}%

\subsubsection{Parameter Values}\label{parameter-values}

The following parameter values were adapted from Qian et al.
(\citeproc{ref-qian2020}{2020}):

\[
\alpha_0 = -2, \quad \alpha_1 = -0.3, \quad \beta_0 = 1, \quad \beta_1 = 0.3,
\]

\[
\sigma_{b0}^2 = 4, \quad \sigma_{b1}^2 = \frac{1}{4}, \quad \sigma_{b2}^2 = 1, \quad \sigma_{b3}^2 = \frac{1}{4}, \quad \sigma_\epsilon^2 = 1.
\]

\subsection{Path Diagrams and Conditional
Independence}\label{path-diagrams-and-conditional-independence}

Qian et al. (\citeproc{ref-qian2020}{2020}) proposes the use of the
conditional independence assumption to identify whether bias may occur,
which is given by:

\[ X_{it} \perp (b_{i0}, b_{i1}) \mid H_{it-1}, A_{it-1}, Y_{it}. \]

where \(H_it\) refers to the history of the set of covariates, which in
this case are all observations of covariate \(X_it\) prior to the
current timepoint \(t\). This allows \(X_{it}\) to be endogenous, but
the endogenous covariate \(X_{it}\) can only depend on the random
effects through variables observed prior to \(X_{it}\). If the only
endogenous covariates are functions of prior treatments and prior
outcomes, then the assumption automatically holds.

When inspecting Figure~\ref{fig-GM1_path} and Figure~\ref{fig-GM2_path},
we may notice that \(X_{it}\) becomes independent of the random effects
after conditioning on \(Y_{it}\). On the other hand, we can see that
this assumption is violated in GM3/3A/3B, as \(X_{it}\) depends directly
on \(b_{i0}\) and can thus not be made independent of the random effects
by conditioning on prior variables such as \(Y_{it}\) (see
Figure~\ref{fig-GM3_path}, Figure~\ref{fig-GM3A_path} and
Figure~\ref{fig-GM3B_path}). Thus, we would expect biased estimates of
the treatment effect for GM3/3A/3B.

\subsection{Backdoor Criterion and
DAGs}\label{backdoor-criterion-and-dags}

DAGs are a useful tool for representing causal relationships between
variables and to evaluate the assumptions needed for causal
identification. According to the backdoor criterion
(\citeproc{ref-pearl1988}{Pearl, 1988}, \citeproc{ref-pearl2009}{2009}),
a requirement for causal identification, causal effects can be
identified by blocking non-causal paths through conditioning on
intermediate variables (e.g., controlling or matching). If any
non-causal paths cannot be blocked due to omitted variables or
measurement error, treatment and outcome remain linked via backdoor
paths, leading to biased estimates of the treatment effect
(\citeproc{ref-Kim2021a}{Kim \& Steiner, 2021}).

We formulated the DAGs in \texttt{dagitty}, where the random disturbance
\(b_{0i}\) was represented by the node U (e.g.,
\citeproc{ref-Kim2021a}{Kim \& Steiner, 2021}). The DAGs for the first
three observations of the three data generating models are presented in
Figure~\ref{fig-DAGs}.

\begin{figure}[H]

\caption{\label{fig-DAGs}DAGs for Generative Models 1, 2, 3/3A/3B (t =
1, 2, 3)}

\begin{minipage}{0.50\linewidth}

\subcaption{\label{fig-GM1_DAG}GM 1}

\centering{

\includegraphics{research-report_files/figure-pdf/fig-GM1_DAG-1.pdf}

}

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}

\subcaption{\label{fig-GM2_DAG}GM 2}

\centering{

\includegraphics{research-report_files/figure-pdf/fig-GM2_DAG-1.pdf}

}

\end{minipage}%
\newline
\begin{minipage}{0.50\linewidth}

\subcaption{\label{fig-GM3_DAG}GM 3, 3A, 3B}

\centering{

\includegraphics{research-report_files/figure-pdf/fig-GM3_DAG-1.pdf}

}

\end{minipage}%
%
\begin{minipage}{0.50\linewidth}
\emph{Note.} The red arrows show the biased backdoor path(s) in the
treatment efffect (before controlling for \(X_{it}\)).\end{minipage}%

\end{figure}%

When applying Pearl's backdoor criterion to GM1/3/3A/3B, it may be
observed that there exists no backdoor path in the treatment effect
\(A_{it} \to Y_{it+1}\), as \(A_{it}\) does not have any parents. While
we need not control for covariate \(X_{it}\) to obtain an unbiased total
effect, doing so should not introduce bias.

On the other hand, in GM2, there is a backdoor path in the treatment
effect: \(A_{it} \leftarrow X_{it} \rightarrow Y_{it+1}\) (see
Figure~\ref{fig-GM2_DAG}). More specifically, \(X_{it}\) is a confounder
in the relationship between \(A_{it}\) and \(Y_{it+1}\). However,
controlling for \(X_{it}\) blocks this backdoor path, making the
treatment effect unbiased. In other words, the history of covariate
\(X_{it}\) is a sufficient adjustment set for the treatment effect.

The results of Qian et al. (\citeproc{ref-qian2020}{2020}) show that GM3
is the only model with bias in the treatment effect. However, the
backdoor criterion failed to identify this bias, as there is no backdoor
path in the treatment effect. This may be explained by the fact that the
DAG does not impose restrictions based on (a) the random slopes and (b)
interaction effects. Concerns regarding the use of Pearl's backdoor
criterion in situations with interaction effects have been voiced by
several people (see Weinberg (\citeproc{ref-weinberg2007}{2007}); Attia
et al. (\citeproc{ref-attia2022}{2022})).

\subsection{Data Analysis}\label{data-analysis}

We evaluated the performance of the models across a total of 30
different settings, each replicated 1,000 times, by systematically
varying the following factors:

\begin{itemize}
\item
  \textbf{Generative Models (GM):} 1, 2, 3, 3A, 3B
\item
  \textbf{Number of timepoints (T):} 10, 30
\item
  \textbf{Sample size (N):} 30, 100, 200
\end{itemize}

All data generation and estimation was performed in \texttt{R}, version
4.4.2 (\citeproc{ref-rcoreteam2024}{Team, 2024}). After the generation
of data generation for any given setting, several models were fit. To
fit the standard MLM, the \texttt{lmer} function from the R-package
\texttt{lme4} (\citeproc{ref-bates2015}{Bates et al., 2015}) was
employed with restricted maximum likelihood estimation. For the MLM, the
analytical models were equivalent to each of the respective
data-generating models. To fit the GEE with the ``exchangeable'',
``independent'' and ``AR(1)'' working correlation structures, the
\texttt{geeglm} function from the R-package \texttt{geepack}
(\citeproc{ref-halekoh2006}{Halekoh et al., 2006}) was employed with the
identity link function. Since the random effects are not explicitly
modelled in GEE, the analytical GEE models simply contain only the fixed
effects of the generative model at hand.

\section{Results}\label{results}

\textbf{?@tbl-simulation\_results} presents the simulation results for
each of the generative and analytical models. The estimates for the
analytical MLM may be interpreted in terms of bias. Here we find that
there is little to no bias for GM1/3a/3b, small bias for GM2 and
substantial bias for GM3. Thus, once we remove either the dependency of
the random intercept with the covariate (GM1), the random slope
\(b_{i2}\) (GM3A) or the interaction \(\beta_1\) (GM3B) from GM3, the
bias dissapears or becomes extremely small. This bias in GM3 decreases
as the number of timepoints \(T\) increases from 10 to 30. Note that the
MLM model fitting success rates are poor for GM2, ranging from 0.92 to
0.09, implying that for the latter case, only 90 of the 1000 models were
fitted.

For the GEE with independence, the values refer to the difference
between the estimated unbiased marginal effect and the specified
conditional effect. Here we find that there is a difference between
these effects of around .09 for GM1, 0.03 for GM3 and close to zero for
GM3A/GM3B.

The GEE models fitted succesfully for all settings.

\begin{table}[H]
    \caption{Simulation results for $N=200$ and $\beta_{0,MLM} = 1$ over $1000$ replications, with $T=10$ and $T=30$.}
    \centering
    \begin{tabular}{@{}p{1.5cm} p{5cm} cc cc@{}}
        \toprule
        GM & Characteristics & \multicolumn{2}{c}{$\hat{\beta}_{0,MLM}-\beta_{0,MLM}$} & \multicolumn{2}{c}{$\hat{\beta}_{0,GEE-ind}-\beta_{0,MLM}$} \\ 
        \cmidrule(lr){3-4} \cmidrule(lr){5-6}
           &                 & \( T = 10 \) & \( T = 30 \) & \( T = 10 \) & \( T = 30 \) \\ \midrule
        1  & Includes random intercept and random slope for treatment & 0.003 & 0.001 & 0.086 & 0.090 \\
        3  & Model 1 with dependency random intercept and covariate       & -0.051 & -0.023 & 0.033 & 0.032 \\
        3a & Model 3 without random slope $b_{2i}$           & 0.002 & -0.000 & -0.001 & -0.000 \\
        3b & Model 3 without interaction effect $\beta_1$ (between treatment and covariate) & 0.005 & 0.001 & 0.003 & 0.001 \\
        \bottomrule
    \end{tabular}
    \label{tab:tbl-simulation_results}
\end{table}

% latex table generated in R 4.4.2 by xtable 1.8-4 package
% Thu Nov 28 15:42:58 2024
\begin{table}[H]
\centering
\begin{tabular}{lrrrrrrrrrrrrrr}
  \hline
GM & T & N & MLM\_bias & MLM\_sd & GEE-Ex\_bias & GEE-Ex\_sd & GEE-AR1\_bias & GEE-AR1\_sd & GEE-Ind\_bias & GEE-Ind\_sd & MLM\_success & GEE-Ex\_success & GEE-AR1\_success & GEE-Ind\_success \\ 
  \hline
1 & 10 & 30 & 0.000 & 0.238 & 0.080 & 0.235 & -0.042 & 0.268 & 0.071 & 0.296 & 1.00 & 1.00 & 1.00 & 1.00 \\ 
  1 & 10 & 100 & -0.012 & 0.129 & 0.071 & 0.129 & -0.037 & 0.142 & 0.074 & 0.169 & 1.00 & 1.00 & 1.00 & 1.00 \\ 
  1 & 10 & 200 & 0.003 & 0.093 & 0.087 & 0.090 & -0.015 & 0.097 & 0.085 & 0.116 & 1.00 & 1.00 & 1.00 & 1.00 \\ 
  1 & 30 & 30 & -0.001 & 0.203 & 0.086 & 0.205 & -0.091 & 0.219 & 0.085 & 0.224 & 1.00 & 1.00 & 1.00 & 1.00 \\ 
  1 & 30 & 100 & -0.007 & 0.107 & 0.084 & 0.110 & -0.106 & 0.134 & 0.083 & 0.123 & 1.00 & 1.00 & 1.00 & 1.00 \\ 
  1 & 30 & 200 & 0.001 & 0.079 & 0.095 & 0.079 & -0.103 & 0.106 & 0.094 & 0.088 & 1.00 & 1.00 & 1.00 & 1.00 \\ 
  \hline
  2 & 10 & 30 & 0.011 & 0.282 & -0.116 & 1.017 & -0.354 & 0.836 & 0.306 & 1.630 & 0.92 & 1.00 & 1.00 & 1.00 \\ 
  2 & 10 & 100 & 0.005 & 0.147 & -0.095 & 1.183 & -0.367 & 0.867 & 0.565 & 1.836 & 0.88 & 1.00 & 1.00 & 1.00 \\ 
  2 & 10 & 200 & 0.008 & 0.103 & 0.066 & 1.219 & -0.248 & 0.892 & 0.935 & 1.887 & 0.84 & 1.00 & 1.00 & 1.00 \\ 
  2 & 30 & 30 & 0.000 & 0.220 & -373.623 & 15220.410 & -7.737 & 6866.989 & 182.565 & 4751.387 & 0.60 & 1.00 & 1.00 & 1.00 \\ 
  2 & 30 & 100 & -0.014 & 0.114 & -891.751 & 35797.928 & -381.111 & 19404.416 & -356.412 & 39799.388 & 0.25 & 1.00 & 1.00 & 1.00 \\ 
  2 & 30 & 200 & -0.013 & 0.087 & 4311.505 & 127396.588 & 2377.454 & 70214.358 & 6319.792 & 136201.790 & 0.09 & 1.00 & 1.00 & 1.00 \\ 
  \hline
  3 & 10 & 30 & -0.052 & 0.245 & 0.031 & 0.230 & -0.122 & 0.223 & 0.020 & 0.249 & 1.00 & 1.00 & 1.00 & 1.00 \\ 
  3 & 10 & 100 & -0.064 & 0.134 & 0.024 & 0.127 & -0.121 & 0.124 & 0.024 & 0.141 & 1.00 & 1.00 & 1.00 & 1.00 \\ 
  3 & 10 & 200 & -0.051 & 0.096 & 0.039 & 0.089 & -0.111 & 0.087 & 0.035 & 0.097 & 1.00 & 1.00 & 1.00 & 1.00 \\ 
  3 & 30 & 30 & -0.024 & 0.206 & 0.032 & 0.202 & -0.124 & 0.182 & 0.030 & 0.208 & 1.00 & 1.00 & 1.00 & 1.00 \\ 
  3 & 30 & 100 & -0.030 & 0.108 & 0.028 & 0.108 & -0.128 & 0.096 & 0.027 & 0.112 & 1.00 & 1.00 & 1.00 & 1.00 \\ 
  3 & 30 & 200 & -0.023 & 0.080 & 0.038 & 0.078 & -0.120 & 0.070 & 0.037 & 0.081 & 1.00 & 1.00 & 1.00 & 1.00 \\ 
   \hline
\end{tabular}
\caption{Results for beta0 bias with Standarddeviation and success rate, 1000 replications, run: GM123-trio-1000reps} 
\label{tab:beta0_bias_sd_success}
\end{table}

% latex table generated in R 4.4.2 by xtable 1.8-4 package
% Thu Nov 28 15:08:39 2024
\begin{table}[H]
\centering
\begin{tabular}{lrrrrrrrrrr}
  \hline
GM & T & N & MLM\_bias & MLM\_sd & GEE-Ex\_bias & GEE-Ex\_sd & GEE-AR1\_bias & GEE-AR1\_sd & GEE-Ind\_bias & GEE-Ind\_sd \\ 
  \hline
3 & 10 & 200 & -0.051 & 0.096 & 0.039 & 0.089 & -0.111 & 0.087 & 0.035 & 0.097 \\ 
  3 & 30 & 200 & -0.023 & 0.080 & 0.038 & 0.078 & -0.120 & 0.070 & 0.037 & 0.081 \\ 
  3a & 10 & 200 & 0.002 & 0.048 & 0.002 & 0.048 & -0.146 & 0.056 & -0.001 & 0.062 \\ 
  3a & 30 & 200 & -0.000 & 0.028 & -0.000 & 0.028 & -0.154 & 0.032 & -0.000 & 0.036 \\ 
  3d & 10 & 200 & 0.005 & 0.087 & 0.005 & 0.087 & -0.195 & 0.080 & 0.003 & 0.097 \\ 
  3d & 30 & 200 & 0.001 & 0.075 & 0.001 & 0.075 & -0.207 & 0.064 & 0.001 & 0.080 \\ 
  3h & 10 & 200 & 0.020 & 0.092 & 0.053 & 0.089 & -0.046 & 0.100 & 0.628 & 0.152 \\ 
  3h & 30 & 200 & 0.003 & 0.078 & 0.042 & 0.078 & -0.053 & 0.084 & 0.673 & 0.144 \\ 
   \hline
\end{tabular}
\caption{Results for beta0 bias with Standarddeviation, 1000 replications, run: GM3adh-trio-1000reps} 
\label{tab:beta0_bias_sd}
\end{table}

\section{Discussion}\label{discussion}

The first research question, pertained to the extent of bias in MLM
estimates of generative model that were nested in GM3. Here, we found
that bias in the treatment effect practically dissapeared when removing
either (1) the dependency between the random intercept and covariate,
(2) the random slope for treatment or (3) the interaction effect. This

\begin{itemize}
\item
  Initially, it seemed that the issue of endogenous covariates meant
  that, for unbiased estimation of the treatment effect, we should rely
  on GEE with independence. However, it is important not to conflate the
  issues mentioned by Qian et al. (\citeproc{ref-qian2020}{2020}). The
  first issue pertains to model interpretation: should we expect
  covariates to be endogenous and be primarily interested in marginal
  interpretations of the parameters rather than the person-specific
  (conditional-on-the-random-effect) interpretation, we should indeed
  employ GEE with working independence (OR STRUCTURAL MARGINAL MODELS???
  CHECK THIS OUT IN ZOTERO). The second issue pertains to model fitting:
  once we conclude that person-specific interpretation aligns with our
  interest but we fear the presence of endogenous covariates, we have to
  assess the conditional independence assumption.
\item
  Despite a violation of the conditional independence assumption in GM
  3, 3A and 3B; biased MLM estimates were only found for GM3.
\item
  Across all generative model, we generally found that the estimated
  fixed treatment effect differed more from the specified MLM effect for
  the analytical GEE models than for the analytical MLM model. This is
  rather unsurprising, considering that the MLM is analyzing the exact
  same model as was specified, thereby putting it at an advantage over
  the GEE.
\item
  For GEE with independence we found the largest difference between the
  estimated marginal and specified conditional effect for GM1,
  indicating that a false interpretation of the MLM parameters as
  marginal, would potentially have the greatest inferential consequences
  compared to the other GMs. For GM3A/3B, such a mistake would not be
  consequential.
\item
  While GEE with independence may indeed yield unbiased estimators of
  the marginal effect as mentioned by Qian et al.
  (\citeproc{ref-qian2020}{2020}), they do not reflect the value of the
  model parameter. And since the endogeneity of a covariate implies that
  it is determined by the random effect, thereby making the marginal
  relationship between any given \(X_{it}\) and \(Y_{it+1}\) different
  as shown by Qian et al. (\citeproc{ref-qian2020}{2020}) (section 2.2),
  it is unclear what utility the combined marginal effect may serve in
  this context.
\item
  For GM2, we noticed extreme model fitting issues for the MLM, due to,
  among other things, a lack of convergence. It should be noted that
  unlike the script used here, Qian et al.
  (\citeproc{ref-qian2020}{2020}) deals only with errors of the
  \texttt{lmer()} function, but not with warnings (e.g., pertaining to
  non-convergence) in their script. This discrepancy may explain the
  slightly different estimates of MLM bias for GM2.
\end{itemize}

They set the same seed for every setting, potentially making the first
dataset the same for every setting. Nevertheless, properly randomizing
does not seem to drastically impact the results. The settings with GM2,
\(T = 30\) and \(N \geq 100\) of Qian et al.
(\citeproc{ref-qian2020}{2020}) results in very implausible values for
the covariate \(X_{it}\) and outcome \(Y_{it+1}\), often exceeding a
million. This may imply the presence of a non-stationary process (e.g.,
unit root). In the case of GEE analytical models, these settings result
in very large estimates.

\begin{itemize}
\tightlist
\item
  \ldots{}
\end{itemize}

\section{To-do}\label{to-do}

\begin{itemize}
\tightlist
\item
  wasn't working exchangeability in GEE equivalent to MLM? then use this
  to argue why using this GEE variation. Because for the difference of
  GEE with independence from the actual specified conditional parameter
  estimates should indicate a difference between the marginal and
  conditional effect, but this is not bias. Can we speak of bias with
  exchangeability?
\end{itemize}

\newpage

\section{References}\label{references}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-attia2022}
Attia, J., Holliday, E., \& Oldmeadow, C. (2022). A proposal for
capturing interaction and effect modification using DAGs.
\emph{International Journal of Epidemiology}, \emph{51}(4), 1047--1053.
\url{https://doi.org/10.1093/ije/dyac126}

\bibitem[\citeproctext]{ref-bates2015}
Bates, D., M√§chler, M., Bolker, B., \& Walker, S. (2015). Fitting linear
mixed-effects models using {lme4}. \emph{Journal of Statistical
Software}, \emph{67}(1), 148.
\url{https://doi.org/10.18637/jss.v067.i01}

\bibitem[\citeproctext]{ref-diggle2002}
Diggle, P. (2002). \emph{Analysis of Longitudinal Data}. OUP Oxford.

\bibitem[\citeproctext]{ref-halekoh2006}
Halekoh, U., H√∏jsgaard, S., \& Yan, J. (2006). The r package geepack for
generalized estimating equations. \emph{Journal of Statistical
Software}, \emph{15/2}, 111.

\bibitem[\citeproctext]{ref-hamaker2020}
Hamaker, E. L., \& Muth√©n, B. (2020). The fixed versus random effects
debate and how it relates to centering in multilevel modeling.
\emph{Psychological Methods}, \emph{25}(3), 365--379.
\url{https://doi.org/10.1037/met0000239}

\bibitem[\citeproctext]{ref-Kim2021a}
Kim, Y., \& Steiner, P. M. (2021). Causal graphical views of fixed
effects and random effects models. \emph{British Journal of Mathematical
and Statistical Psychology}, \emph{74}(2), 165--183.
\url{https://doi.org/10.1111/bmsp.12217}

\bibitem[\citeproctext]{ref-mcneish2017}
McNeish, D., Stapleton, L. M., \& Silverman, R. D. (2017). On the
unnecessary ubiquity of hierarchical linear modeling.
\emph{Psychological Methods}, \emph{22}(1), 114--140.
\url{https://doi.org/10.1037/met0000078}

\bibitem[\citeproctext]{ref-muth2016}
Muth, C., Bales, K. L., Hinde, K., Maninger, N., Mendoza, S. P., \&
Ferrer, E. (2016). Alternative Models for Small Samples in Psychological
Research: Applying Linear Mixed Effects Models and Generalized
Estimating Equations to Repeated Measures Data. \emph{Educational and
Psychological Measurement}, \emph{76}(1), 64--87.
\url{https://doi.org/10.1177/0013164415580432}

\bibitem[\citeproctext]{ref-pearl1988}
Pearl, J. (1988). \emph{Probabilistic Reasoning in Intelligent Systems:
Networks of Plausible Inference}. Morgan Kaufmann.

\bibitem[\citeproctext]{ref-pearl2009}
Pearl, J. (2009). \emph{Causality: Models, reasoning, and inference}
(2nd ed.). Cambridge University Press.

\bibitem[\citeproctext]{ref-qian2020}
Qian, T., Klasnja, P., \& Murphy, S. A. (2020). Linear mixed models with
endogenous covariates: Modeling sequential treatment effects with
application to a mobile health study. \emph{Statistical Science : A
Review Journal of the Institute of Mathematical Statistics},
\emph{35}(3), 375--390. \url{https://doi.org/10.1214/19-sts720}

\bibitem[\citeproctext]{ref-raudenbush2002}
Raudenbush, S. W., \& Bryk, A. S. (2002). \emph{Hierarchical Linear
Models: Applications and Data Analysis Methods} (2nd ed.). SAGE.

\bibitem[\citeproctext]{ref-rcoreteam2024}
Team, R. C. (2024). \emph{R: A language and environment for statistical
computing}. R Foundation for Statistical Computing.
\url{https://www.R-project.org/}

\bibitem[\citeproctext]{ref-weinberg2007}
Weinberg, C. R. (2007). Commentary: Can DAGs clarify effect
modification? \emph{Epidemiology}, \emph{18}(5), 569--572.
\url{https://www.jstor.org/stable/20486428}

\bibitem[\citeproctext]{ref-yan2013}
Yan, J., Aseltine, R. H., \& Harel, O. (2013). Comparing Regression
Coefficients Between Nested Linear Models for Clustered Data With
Generalized Estimating Equations. \emph{Journal of Educational and
Behavioral Statistics}, \emph{38}(2), 172--189.
\url{https://doi.org/10.3102/1076998611432175}

\end{CSLReferences}

\section{Appendix}\label{appendix}

\subsection{Original Section from Qian et al.~(2020): ``4.
Simulation''}\label{original-section-from-qian-et-al.-2020-4.-simulation}

In the simulation, we considered three generative models (GMs), all of
which have an endogenous covariate. In the first two GMs, the endogenous
covariate \(X_{it}\) equals the previous outcome \(Y_{it}\) plus some
random noise, so the conditional independence assumption (10) is valid.
In GM 3, the endogenous covariate depends directly on \(b_i\), violating
assumption (10). The details of the generative models are described
below.

In GM1, we considered a simple case with only a random intercept and a
random slope for \(A_{it}\), so that \(Z_{i(t_0)} = Z_{i(t_2)} = 1\) in
model (7). The outcome is generated as:

\[
Y_{it+1} = \alpha_0 + \alpha_1 X_{it} + b_{i0} + A_{it} (\beta_0 + \beta_1 X_{it} + b_{i2}) + \epsilon_{it+1}.
\]

The random effects \(b_{i0} \sim N(0, \sigma_{b0}^2)\) and
\(b_{i2} \sim N(0, \sigma_{b2}^2)\) are independent of each other. The
covariate is generated as \(X_{i1} \sim N(0, 1)\), and for \(t \geq 2\),

\[
X_{it} = Y_{it} + N(0, 1).
\]

The randomization probability \(p_t\) is constant at \(1/2\). The
exogenous noise is \(\epsilon_{it+1} \sim N(0, \sigma_\epsilon^2)\).

In GM2, we considered the case where \(Z_{i(t_0)} = Z_{i(t_2)} = 1\),
with time-varying randomization probability. The outcome is generated
as:

\[
Y_{it+1} = \alpha_0 + \alpha_1 X_{it} + b_{i0} + b_{i1} X_{it} + A_{it} (\beta_0 + \beta_1 X_{it} + b_{i2} + b_{i3} X_{it}) + \epsilon_{it+1}.
\]

The random effects \(b_{ij} \sim N(0, \sigma_{b_j}^2)\), for
\(0 \leq j \leq 3\), are independent of each other. The covariate is
generated as \(X_{i1} \sim N(0, 1)\), and for \(t \geq 2\),

\[
X_{it} = Y_{it} + N(0, 1).
\]

The randomization probability depends on \(X_{it}\):

\[
p_t = 0.7 \cdot 1(X_{it} > -1.27) + 0.3 \cdot 1(X_{it} \leq -1.27),
\]

where \(1(\cdot)\) represents the indicator function, and the cutoff
\(-1.27\) was chosen so that \(p_t\) equals 0.7 or 0.3 for about half of
the time. The exogenous noise is
\(\epsilon_{it+1} \sim N(0, \sigma_\epsilon^2)\).

GM3 is the same as GM 1, except that the covariate \(X_{it}\) depends
directly on \(b_i\):

\[
X_{i1} \sim N(b_{i0}, 1), \quad X_{it} = Y_{it} + N(b_{i0}, 1) \text{ for } t \geq 2.
\]

We chose the following parameter values:

\[
\alpha_0 = -2, \quad \alpha_1 = -0.3, \quad \beta_0 = 1, \quad \beta_1 = 0.3,
\]

\[
\sigma_{b0}^2 = 4, \quad \sigma_{b1}^2 = \frac{1}{4}, \quad \sigma_{b2}^2 = 1, \quad \sigma_{b3}^2 = \frac{1}{4}, \quad \sigma_\epsilon^2 = 1.
\]

\newpage

\subsection{Overview of Variations on Generative Model
3}\label{overview-of-variations-on-generative-model-3}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2000}}@{}}
\caption{Models with 1 Parameter Less}\tabularnewline
\toprule\noalign{}
\endfirsthead
\endhead
\bottomrule\noalign{}
\endlastfoot
Generative Model & random slope treatment \(b_{i2}\) & interactie
\(\beta_1\) & fixed slope covariate \(\alpha_1\) & bias \\
3 & yes & yes & yes & yes, negative \\
3a & no & yes & yes & no \\
3d & yes & no & yes & no \\
3h & yes & yes & no & yes, positive \\
\end{longtable}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 8\tabcolsep) * \real{0.2000}}@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Generative Model & random slope treatment \(b_{i2}\) & interactie
\(\beta_1\) & fixed slope covariate \(\alpha_1\) & bias \\
3 & yes & yes & yes & yes, negative \\
3b & no & no & yes & no \\
3i & no & yes & no & \\
3j & yes & no & no & \\
\end{longtable}

\subsection{Simulation Plan Proposal}\label{simulation-plan-proposal}

To uncover the undesirable effects of endogenous covariates and
investigate robustness against these effects, we will carry out
simulations in which data will be generated according to several
increasingly complex scenarios. These scenarios will be visually
represented using directed acyclic graphs and analyzed using GEE, MLM
and DSEM. We will start out with a scenario of the basic MLM---where a
time-varying outcome \(Y\) is regressed on a single time-varying
predictor \(X\) and in the presence of stable between person differences
in the intercept---and increase the complexity until we reach the
scenario that includes a time-varying endogenous covariate. The primary
interest of this simulation study is the comparative performance of
different specifications of the MLM and GEE in terms of bias in the
estimation of the effect of \(X\) to \(Y\). The secondary interest is
the efficiency in mean squared error (MSE). We consider settings with
timepoints \(T = 10,30\) and sample size \(N = 30, 100, 200\).

Statistical analyses pertaining to the GEE and basic MLM will be
performed in \texttt{R}, version 4.4.2
(\citeproc{ref-rcoreteam2024}{Team, 2024}). To fit the GEE, the
R-package \texttt{geepack} (\citeproc{ref-halekoh2006}{Halekoh et al.,
2006}) will evaluate several different working correlation structures,
including independent, exchangeable, AR(1) and unstructured. To fit the
basic MLM, the R-package \texttt{lme4} (\citeproc{ref-bates2015}{Bates
et al., 2015}) will be employed, where we will use restricted maximum
likelihood estimation.

\subsection{Trash}\label{trash}

\begin{figure}[H]

\begin{minipage}{0.50\linewidth}
DAG for Generative Models\end{minipage}%

\end{figure}%



\end{document}
